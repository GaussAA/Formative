# ============================================
# Formative 环境变量配置
# ============================================
# 复制此文件为 .env.local 并填入实际值

# LLM 提供商配置
# 支持的提供商: deepseek | qwen | ollama
LLM_PROVIDER=deepseek

# LLM 模型名称
LLM_MODEL=deepseek-chat

# LLM API Key (必需)
# DeepSeek: https://platform.deepseek.com/
# Qwen: https://dashscope.aliyuncs.com/
LLM_API_KEY=your_api_key_here

# LLM API Base URL (可选)
# 如果不填，将根据提供商自动选择默认 URL
# DeepSeek: https://api.deepseek.com/v1
# Qwen: https://dashscope.aliyuncs.com/compatible-mode/v1
# Ollama: http://localhost:11434/v1
LLM_BASE_URL=

# ============================================
# 应用配置
# ============================================

# Node 环境 (通常不需要手动设置)
NODE_ENV=development

# ============================================
# Redis 配置 (可选 - 用于持久化 LangGraph 状态)
# ============================================
# REDIS_URL=redis://localhost:6379
